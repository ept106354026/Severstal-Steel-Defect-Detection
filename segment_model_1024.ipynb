{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a41bba01-133b-4a84-9606-d1f3003a0e5e",
    "_uuid": "30068419-d901-4f8c-864e-6782932a0c91",
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "# <div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#一些套件\" data-toc-modified-id=\"一些套件-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>一些套件</a></span></li><li><span><a href=\"#資料增強跟讀取\" data-toc-modified-id=\"資料增強跟讀取-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>資料增強跟讀取</a></span></li><li><span><a href=\"#損失函數\" data-toc-modified-id=\"損失函數-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>損失函數</a></span></li><li><span><a href=\"#模型\" data-toc-modified-id=\"模型-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>模型</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b54f82aa-6e3b-4abd-9bc4-3c9ddb1cff0c",
    "_uuid": "79435b87-e99f-419b-8c34-e4f97ea5b86c"
   },
   "source": [
    "<input type=\"checkbox\"> U-NET++  \n",
    "<input type=\"checkbox\"> TTA  \n",
    "<input type=\"checkbox\"> Pre-train model  \n",
    "\n",
    "一張圖片切成 22 張 256 * 256 滑動 64，\n",
    "每張一子圖做 8 次 TTA\n",
    "\n",
    "其他\n",
    "- 搞不好可以轉灰階\n",
    "\n",
    "備註\n",
    "- 訓練數據上 label 並沒有重疊\n",
    "- 先把 mask 切好?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5af3d1d0-3bb8-4a0a-87b0-f9f43ab63566",
    "_uuid": "ff2c07af-8ffd-44fc-a74f-b145670bbb39"
   },
   "source": [
    "## 一些套件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "e28b9565-9dbd-4313-87f1-07f0a9ad9b15",
    "_uuid": "2f83ae11-3760-4a47-85c8-c4117c7f3087"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-gpu\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/25/44/47f0722aea081697143fbcf5d2aa60d1aee4aaacb5869aee2b568974777b/tensorflow_gpu-2.0.0-cp36-cp36m-manylinux2010_x86_64.whl (380.8MB)\n",
      "\u001b[K     |################################| 380.8MB 101kB/s  eta 0:00:01    |#########                       | 114.7MB 1.5MB/s eta 0:02:57     |#########################       | 309.2MB 28.2MB/s eta 0:00:03     |############################    | 339.2MB 24.8MB/s eta 0:00:02\n",
      "\u001b[?25hCollecting keras-applications>=1.0.8 (from tensorflow-gpu)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
      "\u001b[K     |################################| 51kB 22.3MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-pasta>=0.1.6 (from tensorflow-gpu)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/33/376510eb8d6246f3c30545f416b2263eee461e40940c2a4413c711bdf62d/google_pasta-0.1.7-py3-none-any.whl (52kB)\n",
      "\u001b[K     |################################| 61kB 36.9MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow-gpu) (1.12.0)\n",
      "Collecting keras-preprocessing>=1.0.5 (from tensorflow-gpu)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/28/6a/8c1f62c37212d9fc441a7e26736df51ce6f0e38455816445471f10da4f0a/Keras_Preprocessing-1.1.0-py2.py3-none-any.whl (41kB)\n",
      "\u001b[K     |################################| 51kB 33.5MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting grpcio>=1.8.6 (from tensorflow-gpu)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e8/cb/ebf7b54c5d4ad521d88ee7826dfa0fc3ac84502361ad7e5cb739ea5057a4/grpcio-1.24.1-cp36-cp36m-manylinux1_x86_64.whl (2.3MB)\n",
      "\u001b[K     |################################| 2.3MB 43.6MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.6/site-packages (from tensorflow-gpu) (0.33.4)\n",
      "Collecting gast==0.2.2 (from tensorflow-gpu)\n",
      "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow-gpu) (1.16.4)\n",
      "Collecting protobuf>=3.6.1 (from tensorflow-gpu)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/52/d8d2dbff74b8bf517c42db8d44c3f9ef6555e6f5d6caddfa3f207b9143df/protobuf-3.10.0-cp36-cp36m-manylinux1_x86_64.whl (1.3MB)\n",
      "\u001b[K     |################################| 1.3MB 46.0MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-estimator<2.1.0,>=2.0.0 (from tensorflow-gpu)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fc/08/8b927337b7019c374719145d1dceba21a8bb909b93b1ad6f8fb7d22c1ca1/tensorflow_estimator-2.0.1-py2.py3-none-any.whl (449kB)\n",
      "\u001b[K     |################################| 450kB 36.6MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting opt-einsum>=2.3.2 (from tensorflow-gpu)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b8/83/755bd5324777875e9dff19c2e59daec837d0378c09196634524a3d7269ac/opt_einsum-3.1.0.tar.gz (69kB)\n",
      "\u001b[K     |################################| 71kB 37.4MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting wrapt>=1.11.1 (from tensorflow-gpu)\n",
      "  Downloading https://files.pythonhosted.org/packages/23/84/323c2415280bc4fc880ac5050dddfb3c8062c2552b34c2e512eb4aa68f79/wrapt-1.11.2.tar.gz\n",
      "Collecting tensorboard<2.1.0,>=2.0.0 (from tensorflow-gpu)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/a6/e8ffa4e2ddb216449d34cfcb825ebb38206bee5c4553d69e7bc8bc2c5d64/tensorboard-2.0.0-py3-none-any.whl (3.8MB)\n",
      "\u001b[K     |################################| 3.8MB 35.9MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting termcolor>=1.1.0 (from tensorflow-gpu)\n",
      "  Downloading https://files.pythonhosted.org/packages/8a/48/a76be51647d0eb9f10e2a4511bf3ffb8cc1e6b14e9e4fab46173aa79f981/termcolor-1.1.0.tar.gz\n",
      "Collecting astor>=0.6.0 (from tensorflow-gpu)\n",
      "  Downloading https://files.pythonhosted.org/packages/d1/4f/950dfae467b384fc96bc6469de25d832534f6b4441033c39f914efd13418/astor-0.8.0-py2.py3-none-any.whl\n",
      "Collecting absl-py>=0.7.0 (from tensorflow-gpu)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3b/72/e6e483e2db953c11efa44ee21c5fdb6505c4dffa447b4263ca8af6676b62/absl-py-0.8.1.tar.gz (103kB)\n",
      "\u001b[K     |################################| 112kB 61.4MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting h5py (from keras-applications>=1.0.8->tensorflow-gpu)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/06/cafdd44889200e5438b897388f3075b52a8ef01f28a17366d91de0fa2d05/h5py-2.10.0-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n",
      "\u001b[K     |################################| 2.9MB 38.1MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /opt/conda/lib/python3.6/site-packages (from protobuf>=3.6.1->tensorflow-gpu) (41.0.1)\n",
      "Collecting werkzeug>=0.11.15 (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ce/42/3aeda98f96e85fd26180534d36570e4d18108d62ae36f87694b476b83d6f/Werkzeug-0.16.0-py2.py3-none-any.whl (327kB)\n",
      "\u001b[K     |################################| 327kB 50.2MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting markdown>=2.6.8 (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c0/4e/fd492e91abdc2d2fcb70ef453064d980688762079397f779758e055f6575/Markdown-3.1.1-py2.py3-none-any.whl (87kB)\n",
      "\u001b[K     |################################| 92kB 35.8MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: gast, opt-einsum, wrapt, termcolor, absl-py\n",
      "  Building wheel for gast (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7541 sha256=1d88706ace44cf10b860c27f061e9a54919fe3fa5a48df5c003d5aa152d46ae8\n",
      "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
      "  Building wheel for opt-einsum (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for opt-einsum: filename=opt_einsum-3.1.0-cp36-none-any.whl size=61682 sha256=425e6dc9846b9d38701768e7a3f567cbaa9963cd5b310421e5b6db126eebbb63\n",
      "  Stored in directory: /root/.cache/pip/wheels/2c/b1/94/43d03e130b929aae7ba3f8d15cbd7bc0d1cb5bb38a5c721833\n",
      "  Building wheel for wrapt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wrapt: filename=wrapt-1.11.2-cp36-cp36m-linux_x86_64.whl size=66141 sha256=eb759fdb39a4e4675fd61ad36a3044f00f75fdd2805261d99413d9180b027102\n",
      "  Stored in directory: /root/.cache/pip/wheels/d7/de/2e/efa132238792efb6459a96e85916ef8597fcb3d2ae51590dfd\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for termcolor: filename=termcolor-1.1.0-cp36-none-any.whl size=4833 sha256=1b1deb3e959117cfae560dc675870091b035135ada39c3ac6efd4b264530dee7\n",
      "  Stored in directory: /root/.cache/pip/wheels/7c/06/54/bc84598ba1daf8f970247f550b175aaaee85f68b4b0c5ab2c6\n",
      "  Building wheel for absl-py (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for absl-py: filename=absl_py-0.8.1-cp36-none-any.whl size=121168 sha256=18c38c6717cc4ea5693b5a25b4ea35864c2b9d116a595698739f25934c11de8b\n",
      "  Stored in directory: /root/.cache/pip/wheels/a7/15/a0/0a0561549ad11cdc1bc8fa1191a353efd30facf6bfb507aefc\n",
      "Successfully built gast opt-einsum wrapt termcolor absl-py\n",
      "Installing collected packages: h5py, keras-applications, google-pasta, keras-preprocessing, grpcio, gast, protobuf, tensorflow-estimator, opt-einsum, wrapt, werkzeug, absl-py, markdown, tensorboard, termcolor, astor, tensorflow-gpu\n",
      "Successfully installed absl-py-0.8.1 astor-0.8.0 gast-0.2.2 google-pasta-0.1.7 grpcio-1.24.1 h5py-2.10.0 keras-applications-1.0.8 keras-preprocessing-1.1.0 markdown-3.1.1 opt-einsum-3.1.0 protobuf-3.10.0 tensorboard-2.0.0 tensorflow-estimator-2.0.1 tensorflow-gpu-2.0.0 termcolor-1.1.0 werkzeug-0.16.0 wrapt-1.11.2\n",
      "\u001b[33mWARNING: You are using pip version 19.2.2, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting keras\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/fd/6bfe87920d7f4fd475acd28500a42482b6b84479832bdc0fe9e589a60ceb/Keras-2.3.1-py2.py3-none-any.whl (377kB)\n",
      "\u001b[K     |################################| 378kB 45.0MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.6/site-packages (from keras) (1.12.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.6/site-packages (from keras) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.6/site-packages (from keras) (1.16.4)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /opt/conda/lib/python3.6/site-packages (from keras) (1.0.8)\n",
      "Collecting scipy>=0.14 (from keras)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/50/a552a5aff252ae915f522e44642bb49a7b7b31677f9580cfd11bcc869976/scipy-1.3.1-cp36-cp36m-manylinux1_x86_64.whl (25.2MB)\n",
      "\u001b[K     |################################| 25.2MB 1.0MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: h5py in /opt/conda/lib/python3.6/site-packages (from keras) (2.10.0)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.6/site-packages (from keras) (5.1)\n",
      "Installing collected packages: scipy, keras\n",
      "Successfully installed keras-2.3.1 scipy-1.3.1\n",
      "\u001b[33mWARNING: You are using pip version 19.2.2, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting opencv-python\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/7e/bd5425f4dacb73367fddc71388a47c1ea570839197c2bcad86478e565186/opencv_python-4.1.1.26-cp36-cp36m-manylinux1_x86_64.whl (28.7MB)\n",
      "\u001b[K     |################################| 28.7MB 8.4MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.11.3 in /opt/conda/lib/python3.6/site-packages (from opencv-python) (1.16.4)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.1.1.26\n",
      "\u001b[33mWARNING: You are using pip version 19.2.2, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting matplotlib\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/57/4f/dd381ecf6c6ab9bcdaa8ea912e866dedc6e696756156d8ecc087e20817e2/matplotlib-3.1.1-cp36-cp36m-manylinux1_x86_64.whl (13.1MB)\n",
      "\u001b[K     |################################| 13.1MB 58.8MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 (from matplotlib)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/11/fa/0160cd525c62d7abd076a070ff02b2b94de589f1a9789774f17d7c54058e/pyparsing-2.4.2-py2.py3-none-any.whl (65kB)\n",
      "\u001b[K     |################################| 71kB 29.0MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading https://files.pythonhosted.org/packages/f7/d2/e07d3ebb2bd7af696440ce7e754c59dd546ffe1bbe732c8ab68b9c834e61/cycler-0.10.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: numpy>=1.11 in /opt/conda/lib/python3.6/site-packages (from matplotlib) (1.16.4)\n",
      "Collecting kiwisolver>=1.0.1 (from matplotlib)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f8/a1/5742b56282449b1c0968197f63eae486eca2c35dcd334bab75ad524e0de1/kiwisolver-1.1.0-cp36-cp36m-manylinux1_x86_64.whl (90kB)\n",
      "\u001b[K     |################################| 92kB 37.4MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib) (2.8.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from cycler>=0.10->matplotlib) (1.12.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.6/site-packages (from kiwisolver>=1.0.1->matplotlib) (41.0.1)\n",
      "Installing collected packages: pyparsing, cycler, kiwisolver, matplotlib\n",
      "Successfully installed cycler-0.10.0 kiwisolver-1.1.0 matplotlib-3.1.1 pyparsing-2.4.2\n",
      "\u001b[33mWARNING: You are using pip version 19.2.2, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting pandas\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/86/12/08b092f6fc9e4c2552e37add0861d0e0e0d743f78f1318973caad970b3fc/pandas-0.25.2-cp36-cp36m-manylinux1_x86_64.whl (10.4MB)\n",
      "\u001b[K     |################################| 10.4MB 4.4MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.6/site-packages (from pandas) (2019.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /opt/conda/lib/python3.6/site-packages (from pandas) (1.16.4)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /opt/conda/lib/python3.6/site-packages (from pandas) (2.8.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.6/site-packages (from python-dateutil>=2.6.1->pandas) (1.12.0)\n",
      "Installing collected packages: pandas\n",
      "Successfully installed pandas-0.25.2\n",
      "\u001b[33mWARNING: You are using pip version 19.2.2, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting segmentation-models\n",
      "  Downloading https://files.pythonhosted.org/packages/70/14/090ea95a4f69c453731d9df3feff0a08e0dea0e8dff932dc4839ec4dab5c/segmentation_models-1.0.0-py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: keras-applications<=1.0.8,>=1.0.7 in /opt/conda/lib/python3.6/site-packages (from segmentation-models) (1.0.8)\n",
      "Collecting image-classifiers==1.0.0 (from segmentation-models)\n",
      "  Downloading https://files.pythonhosted.org/packages/81/98/6f84720e299a4942ab80df5f76ab97b7828b24d1de5e9b2cbbe6073228b7/image_classifiers-1.0.0-py3-none-any.whl\n",
      "Collecting efficientnet==1.0.0 (from segmentation-models)\n",
      "  Downloading https://files.pythonhosted.org/packages/97/82/f3ae07316f0461417dc54affab6e86ab188a5a22f33176d35271628b96e0/efficientnet-1.0.0-py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.9.1 in /opt/conda/lib/python3.6/site-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation-models) (1.16.4)\n",
      "Requirement already satisfied, skipping upgrade: h5py in /opt/conda/lib/python3.6/site-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation-models) (2.10.0)\n",
      "Collecting scikit-image (from efficientnet==1.0.0->segmentation-models)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/05/4c/79516d5c800d9ef00ce59c344e0f7d3c7d7b8374b0341811a3b531d02c72/scikit_image-0.16.1-cp36-cp36m-manylinux1_x86_64.whl (26.5MB)\n",
      "\u001b[K     |################################| 26.5MB 1.2MB/s eta 0:00:01     |##########################      | 21.9MB 1.2MB/s eta 0:00:04\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: six in /opt/conda/lib/python3.6/site-packages (from h5py->keras-applications<=1.0.8,>=1.0.7->segmentation-models) (1.12.0)\n",
      "Collecting pillow>=4.3.0 (from scikit-image->efficientnet==1.0.0->segmentation-models)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/10/5c/0e94e689de2476c4c5e644a3bd223a1c1b9e2bdb7c510191750be74fa786/Pillow-6.2.1-cp36-cp36m-manylinux1_x86_64.whl (2.1MB)\n",
      "\u001b[K     |################################| 2.1MB 38.1MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: matplotlib!=3.0.0,>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (3.1.1)\n",
      "Collecting PyWavelets>=0.4.0 (from scikit-image->efficientnet==1.0.0->segmentation-models)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/59/bb/d2b85265ec9fa3c1922210c9393d4cdf7075cc87cce6fe671d7455f80fbc/PyWavelets-1.1.1-cp36-cp36m-manylinux1_x86_64.whl (4.4MB)\n",
      "\u001b[K     |################################| 4.4MB 39.9MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: scipy>=0.19.0 in /opt/conda/lib/python3.6/site-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (1.3.1)\n",
      "Collecting imageio>=2.3.0 (from scikit-image->efficientnet==1.0.0->segmentation-models)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/de/f7f985018f462ceeffada7f6e609919fbcc934acd9301929cba14bc2c24a/imageio-2.6.1-py3-none-any.whl (3.3MB)\n",
      "\u001b[K     |################################| 3.3MB 47.4MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting networkx>=2.0 (from scikit-image->efficientnet==1.0.0->segmentation-models)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/41/8f/dd6a8e85946def36e4f2c69c84219af0fa5e832b018c970e92f2ad337e45/networkx-2.4-py3-none-any.whl (1.6MB)\n",
      "\u001b[K     |################################| 1.6MB 42.6MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: cycler>=0.10 in /opt/conda/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (0.10.0)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (2.4.2)\n",
      "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (2.8.0)\n",
      "Requirement already satisfied, skipping upgrade: decorator>=4.3.0 in /opt/conda/lib/python3.6/site-packages (from networkx>=2.0->scikit-image->efficientnet==1.0.0->segmentation-models) (4.4.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /opt/conda/lib/python3.6/site-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (41.0.1)\n",
      "Installing collected packages: image-classifiers, pillow, PyWavelets, imageio, networkx, scikit-image, efficientnet, segmentation-models\n",
      "Successfully installed PyWavelets-1.1.1 efficientnet-1.0.0 image-classifiers-1.0.0 imageio-2.6.1 networkx-2.4 pillow-6.2.1 scikit-image-0.16.1 segmentation-models-1.0.0\n",
      "\u001b[33mWARNING: You are using pip version 19.2.2, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-gpu\n",
    "!pip install keras\n",
    "!pip install opencv-python\n",
    "!pip install matplotlib\n",
    "!pip install pandas\n",
    "!pip install -U segmentation-models\n",
    "# !pip install keras --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "557aadc3-b3d3-4a81-b65e-331a2d7a881a",
    "_uuid": "69db4a63-6b1d-4fbf-9a8a-c2761c5447b2"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import cv2\n",
    "import os\n",
    "# print(os.listdir('/home'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "d68c3e04-dbf5-4277-809c-1f77c6e5a2d4",
    "_uuid": "35ea6ee0-ec98-42b5-b801-93f9d1f63ea4"
   },
   "outputs": [],
   "source": [
    "# os.chdir('../input/severstal-steel-defect-detection')\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "train['ImageId_ClassId_1'] = train['ImageId_ClassId'].apply(lambda t :t[:-2])\n",
    "train.set_index('ImageId_ClassId_1',inplace=True)\n",
    "\n",
    "train.EncodedPixels[train.EncodedPixels.isnull()]=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "de53cd02-3721-449e-b039-7f4cd171d177",
    "_uuid": "b0e0ccca-549c-4e56-995a-5694c2ba364e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    5150\n",
       "1     897\n",
       "4     801\n",
       "2     247\n",
       "Name: ImageId_ClassId, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看異常比例\n",
    "train[train.EncodedPixels!=-1].ImageId_ClassId.apply(lambda t: t[-1:]).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "f60c539d-0557-46a2-9ef5-753cddcbd755",
    "_uuid": "4ed9e397-71af-4eb8-b8a3-6bd567907b30"
   },
   "outputs": [],
   "source": [
    "base_path='train_images'\n",
    "batch_size = 32\n",
    "df = train\n",
    "img_list = os.listdir('train_images/')\n",
    "img_list_random = np.random.permutation(img_list)\n",
    "train_img, val_img = img_list_random[:10000], img_list_random[10000:]\n",
    "n_classes = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "92a9ffd4-d559-43c1-b432-e00bc88abb71",
    "_uuid": "c2786224-afb4-4b21-9de7-093288d0bace"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "df = train\n",
    "width = 1600\n",
    "height = 256\n",
    "classes = 5\n",
    "dim = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "9e1ac50c-7db6-4fe8-bc3c-c4296505e233",
    "_uuid": "c1c13213-c125-4338-aca1-09fb0b9b1640"
   },
   "source": [
    "## 資料增強跟讀取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "70b47f31-9e9e-4967-94ba-77f9360fe611",
    "_uuid": "ac687a54-36a2-4939-be79-54d8b7fbf646"
   },
   "outputs": [],
   "source": [
    "def random_argument(img,mask):\n",
    "    # 隨機 256 x 256 的圖片\n",
    "#     c = np.random.choice(1600-256)\n",
    "    flip = np.random.choice([0,1])\n",
    "#     rot = np.random.choice([0,1,2,3])\n",
    "    rot = np.random.choice([0,2])\n",
    "#     img = img[:,c:c+256]\n",
    "#     mask = mask[:,c:c+256]\n",
    "    img = np.rot90(img,rot)\n",
    "    mask = np.rot90(mask,rot)\n",
    "    if flip == 1:\n",
    "        img = np.fliplr(img)\n",
    "        mask = np.fliplr(mask)\n",
    "    return img,mask\n",
    "\n",
    "def rle2mask(rle, imgshape):\n",
    "    \n",
    "    if rle!=-1:\n",
    "#         print('a')\n",
    "        width = imgshape[0]\n",
    "        height= imgshape[1]\n",
    "\n",
    "        mask= np.zeros( width*height ).astype(np.uint8)\n",
    "\n",
    "        array = np.asarray([int(x) for x in rle.split()])\n",
    "        starts = array[0::2]\n",
    "        lengths = array[1::2]\n",
    "\n",
    "        for index, start in enumerate(starts):\n",
    "            mask[int(start):int(start+lengths[index])] = 1\n",
    "\n",
    "        return np.flipud( np.rot90( mask.reshape(height,width), k=1 ) )\n",
    "    else:\n",
    "        return np.zeros((256,1600))\n",
    "\n",
    "def build_masks(rles, input_shape):\n",
    "#     depth = len(rles)+1\n",
    "    depth = len(rles)\n",
    "    height, width = input_shape\n",
    "    masks = np.zeros((height, width, depth))\n",
    "    \n",
    "    for i, rle in enumerate(rles):\n",
    "        if type(rle) is str:\n",
    "            masks[:, :, i] = rle2mask(rle, (height, width))\n",
    "#     # 加入正常鋼鐵類別\n",
    "#     masks[:, :, depth-1] = -masks.sum(axis=2)+1\n",
    "    \n",
    "    return masks\n",
    "\n",
    "def mask2rle(img):\n",
    "    '''\n",
    "    img: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "    pixels= img.T.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0]\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "def build_rles(masks):\n",
    "    width, height, depth = masks.shape\n",
    "    \n",
    "    rles = [mask2rle(masks[:, :, i])\n",
    "            for i in range(depth-1)] # 不計算第五類(正常鋼鐵) \n",
    "    return rles\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "28b78457-77e0-4fe1-a298-54c015876ba0",
    "_uuid": "d7099739-cfce-4576-a68b-94307d006e47"
   },
   "source": [
    "## 損失函數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "e05e0912-7ff1-4d63-bfd2-a9cd71e58f1c",
    "_uuid": "5d41dfe2-b451-4c67-a4c9-5acae97f355e"
   },
   "outputs": [],
   "source": [
    "def Tversky_Loss(y_true, y_pred, smooth = 1, alpha = 0.3, beta = 0.7, flatten = False):\n",
    "    \n",
    "    if flatten:\n",
    "        y_true = K.flatten(y_true)\n",
    "        y_pred = K.flatten(y_pred)\n",
    "    \n",
    "    TP = K.sum(y_true * y_pred)\n",
    "    FP = K.sum((1-y_true) * y_pred)\n",
    "    FN = K.sum(y_true * (1-y_pred))\n",
    "    \n",
    "    tversky_coef = (TP + smooth) / (TP + alpha * FP + beta * FN + smooth)\n",
    "    \n",
    "    return 1 - tversky_coef\n",
    "\n",
    "def Focal_Loss(y_true, y_pred, alpha = 0.8, gamma = 2.0, flatten = False):\n",
    "    \n",
    "    if flatten:\n",
    "        y_true = K.flatten(y_true)\n",
    "        y_pred = K.flatten(y_pred)    \n",
    "    \n",
    "    bce = keras.losses.binary_crossentropy(y_true, y_pred)\n",
    "    bce_exp = K.exp(-bce)\n",
    "    \n",
    "    loss = K.mean(alpha * K.pow((1-bce_exp), gamma) * bce)\n",
    "    return loss\n",
    "\n",
    "def weighted_bce(weight = 0.6):\n",
    "    \n",
    "    def convert_2_logits(y_pred):\n",
    "        y_pred = tf.clip_by_value(y_pred, K.epsilon(), 1 - K.epsilon())\n",
    "        return tf.log(y_pred / (1-y_pred))\n",
    "    \n",
    "    def weighted_binary_crossentropy(y_true, y_pred):\n",
    "        y_pred = convert_2_logits(y_pred)\n",
    "        loss = tf.nn.weighted_cross_entropy_with_logits(logits = y_pred, targets = y_true, pos_weight = weight)\n",
    "        return loss\n",
    "    \n",
    "    return weighted_binary_crossentropy\n",
    "\n",
    "def Combo_Loss(y_true, y_pred, a = 0.4, b = 0.2, c= 0.4):\n",
    "    \n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    \n",
    "    return a*weighted_bce()(y_true, y_pred) + b*Focal_Loss(y_true_f, y_pred_f) + c*Tversky_Loss(y_true_f, y_pred_f)\n",
    "\n",
    "def Dice_coef(y_true, y_pred, smooth = 1):\n",
    "\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    " \n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def Dice_loss(y_true, y_pred):   \n",
    "    return  1.0 - Dice_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "10df696f-5be8-47aa-8455-32b59d61dc77",
    "_uuid": "07efed39-2d42-4df6-89bb-cc536c7f5e06"
   },
   "source": [
    "## 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "679ec2a4-04ec-49a6-8d2a-e1e8451acc65",
    "_uuid": "06f36576-09fc-48fb-b3ae-472d55b16ec3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation Models: using `keras` framework.\n"
     ]
    }
   ],
   "source": [
    "import segmentation_models as sm\n",
    "import keras.backend as K\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "BACKBONE = 'efficientnetb5'\n",
    "preprocess_input = sm.get_preprocessing(BACKBONE)\n",
    "def build_masks(rles, input_shape):\n",
    "    depth = len(rles)\n",
    "    height, width = input_shape\n",
    "    masks = np.zeros((height, width, depth))\n",
    "    \n",
    "    for i, rle in enumerate(rles):\n",
    "        if type(rle) is str:\n",
    "            masks[:, :, i] = rle2mask(rle, (height, width))\n",
    "    # 加入正常鋼鐵類別\n",
    "#     masks[:, :, depth-1] = -masks.sum(axis=2)+1\n",
    "    \n",
    "    return masks\n",
    "\n",
    "def data_generator(ID_list, width = 1600, height = 256, classes = 4,\n",
    "                   dim = 3, batch_size=4):\n",
    "    while True:\n",
    "\n",
    "        choice_img = np.random.choice(ID_list,size=batch_size) # 因資料增強，不須抽出不放回\n",
    "        df = train.loc[choice_img]\n",
    "        X = np.empty((batch_size,height,1600,dim))\n",
    "        Target = np.empty((batch_size,height,1600,classes))\n",
    "        for i, img_jpg in enumerate(choice_img):\n",
    "            rles = train.loc[img_jpg,'EncodedPixels']\n",
    "            img = cv2.imread('train_images/'+img_jpg)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # 轉成 PGB\n",
    "#             img = img.astype(np.float32) / 255. # 標準化\n",
    "            img = preprocess_input(img)\n",
    "            mask = build_masks(rles,(height,width))\n",
    "            img,mask = random_argument(img,mask)\n",
    "#             print(mask.shape,img.shape)\n",
    "            X[i,] = img\n",
    "            Target[i,] = mask\n",
    "\n",
    "        yield X,Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "9fa0c864-41be-4e5a-9f7d-07d808ddac58",
    "_uuid": "d22d8cf9-4e62-44bb-b1dc-b3a7062850f9"
   },
   "outputs": [],
   "source": [
    "\n",
    "model = sm.FPN(BACKBONE, input_shape=(256, 1600, 3), \n",
    "               encoder_weights='imagenet',\n",
    "               classes=4, activation='sigmoid')\n",
    "model.compile(\n",
    "    'Adam',\n",
    "    loss=sm.losses.binary_focal_dice_loss,\n",
    "    metrics=[Dice_coef,sm.metrics.IOUScore(),sm.metrics.f1_score],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_generator = data_generator(train_img,batch_size=4)\n",
    "val_generator = data_generator(val_img,batch_size=4)\n",
    "z = next(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 256, 1600, 4)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "16eba7fd-2fb0-453e-8fcb-62bd3ef5f595",
    "_uuid": "d10b83b8-bbde-458e-854a-20c9c341a689"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000000\n",
      "100/100 [==============================] - 176s 2s/step - loss: 1.0415 - Dice_coef: 0.1879 - iou_score: 0.0444 - f1-score: 0.0706 - val_loss: 1.1011 - val_Dice_coef: 0.1981 - val_iou_score: 0.0411 - val_f1-score: 0.0657\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.10113, saving model to model_10241248.h5\n",
      "Epoch 2/2000000\n",
      "100/100 [==============================] - 166s 2s/step - loss: 0.9595 - Dice_coef: 0.2341 - iou_score: 0.0641 - f1-score: 0.0993 - val_loss: 1.0926 - val_Dice_coef: 0.2052 - val_iou_score: 0.0618 - val_f1-score: 0.0969\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.10113 to 1.09259, saving model to model_10241248.h5\n",
      "Epoch 3/2000000\n",
      "100/100 [==============================] - 169s 2s/step - loss: 0.9621 - Dice_coef: 0.2501 - iou_score: 0.0697 - f1-score: 0.1063 - val_loss: 0.9373 - val_Dice_coef: 0.2466 - val_iou_score: 0.0571 - val_f1-score: 0.0897\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.09259 to 0.93730, saving model to model_10241248.h5\n",
      "Epoch 4/2000000\n",
      "100/100 [==============================] - 162s 2s/step - loss: 0.9469 - Dice_coef: 0.3073 - iou_score: 0.0772 - f1-score: 0.1166 - val_loss: 0.9501 - val_Dice_coef: 0.2981 - val_iou_score: 0.0861 - val_f1-score: 0.1258\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.93730\n",
      "Epoch 5/2000000\n",
      "100/100 [==============================] - 166s 2s/step - loss: 0.9351 - Dice_coef: 0.3278 - iou_score: 0.0822 - f1-score: 0.1204 - val_loss: 0.8624 - val_Dice_coef: 0.4668 - val_iou_score: 0.1091 - val_f1-score: 0.1495\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.93730 to 0.86237, saving model to model_10241248.h5\n",
      "Epoch 6/2000000\n",
      "100/100 [==============================] - 168s 2s/step - loss: 0.9159 - Dice_coef: 0.3632 - iou_score: 0.1009 - f1-score: 0.1459 - val_loss: 1.3663 - val_Dice_coef: 0.2337 - val_iou_score: 0.0822 - val_f1-score: 0.1236\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.86237\n",
      "Epoch 7/2000000\n",
      "100/100 [==============================] - 167s 2s/step - loss: 0.9186 - Dice_coef: 0.3615 - iou_score: 0.0947 - f1-score: 0.1376 - val_loss: 1.0305 - val_Dice_coef: 0.1453 - val_iou_score: 0.0586 - val_f1-score: 0.0893\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.86237\n",
      "Epoch 8/2000000\n",
      " 27/100 [=======>......................] - ETA: 1:40 - loss: 0.9092 - Dice_coef: 0.3074 - iou_score: 0.0869 - f1-score: 0.1297"
     ]
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint(\n",
    "    'model_10241248.h5', \n",
    "    monitor='val_loss', \n",
    "    verbose=1, \n",
    "    save_best_only=True, \n",
    "    save_weights_only=False,\n",
    "    mode='auto'\n",
    ")\n",
    "\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_generator, steps_per_epoch=100, epochs=2000000,\n",
    "    validation_data=val_generator, validation_steps=50,\n",
    "    callbacks=[checkpoint,EarlyStopping(patience=20)],\n",
    "    use_multiprocessing=True,\n",
    "    workers=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000000\n",
      "1000/1000 [==============================] - 548s 548ms/step - loss: 0.9143 - Dice_coef: 0.3627 - iou_score: 0.0975 - f1-score: 0.1355 - val_loss: 1.0692 - val_Dice_coef: 0.3609 - val_iou_score: 0.0874 - val_f1-score: 0.1197\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.82654\n",
      "Epoch 2/2000000\n",
      "1000/1000 [==============================] - 546s 546ms/step - loss: 0.9141 - Dice_coef: 0.3637 - iou_score: 0.0972 - f1-score: 0.1345 - val_loss: 1.0112 - val_Dice_coef: 0.3666 - val_iou_score: 0.0885 - val_f1-score: 0.1247\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.82654\n",
      "Epoch 3/2000000\n",
      "1000/1000 [==============================] - 547s 547ms/step - loss: 0.9104 - Dice_coef: 0.3771 - iou_score: 0.1000 - f1-score: 0.1378 - val_loss: 0.6990 - val_Dice_coef: 0.3661 - val_iou_score: 0.0997 - val_f1-score: 0.1375\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.82654 to 0.69899, saving model to model_10231756.h5\n",
      "Epoch 4/2000000\n",
      "1000/1000 [==============================] - 545s 545ms/step - loss: 0.9034 - Dice_coef: 0.3923 - iou_score: 0.1038 - f1-score: 0.1419 - val_loss: 0.9945 - val_Dice_coef: 0.3029 - val_iou_score: 0.1006 - val_f1-score: 0.1369\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.69899\n",
      "Epoch 5/2000000\n",
      "1000/1000 [==============================] - 546s 546ms/step - loss: 0.9062 - Dice_coef: 0.3903 - iou_score: 0.1043 - f1-score: 0.1419 - val_loss: 0.8672 - val_Dice_coef: 0.3777 - val_iou_score: 0.0943 - val_f1-score: 0.1290\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.69899\n",
      "Epoch 6/2000000\n",
      "1000/1000 [==============================] - 546s 546ms/step - loss: 0.8991 - Dice_coef: 0.4049 - iou_score: 0.1077 - f1-score: 0.1457 - val_loss: 0.9702 - val_Dice_coef: 0.4035 - val_iou_score: 0.1058 - val_f1-score: 0.1407\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.69899\n",
      "Epoch 7/2000000\n",
      "1000/1000 [==============================] - 546s 546ms/step - loss: 0.8951 - Dice_coef: 0.3981 - iou_score: 0.1125 - f1-score: 0.1526 - val_loss: 1.0787 - val_Dice_coef: 0.3874 - val_iou_score: 0.1009 - val_f1-score: 0.1368\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.69899\n",
      "Epoch 8/2000000\n",
      "1000/1000 [==============================] - 546s 546ms/step - loss: 0.8886 - Dice_coef: 0.4242 - iou_score: 0.1151 - f1-score: 0.1546 - val_loss: 0.7679 - val_Dice_coef: 0.3527 - val_iou_score: 0.1131 - val_f1-score: 0.1508\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.69899\n",
      "Epoch 9/2000000\n",
      "1000/1000 [==============================] - 546s 546ms/step - loss: 0.8870 - Dice_coef: 0.4235 - iou_score: 0.1154 - f1-score: 0.1547 - val_loss: 0.9905 - val_Dice_coef: 0.4549 - val_iou_score: 0.1158 - val_f1-score: 0.1512\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.69899\n",
      "Epoch 10/2000000\n",
      "1000/1000 [==============================] - 546s 546ms/step - loss: 0.8873 - Dice_coef: 0.4349 - iou_score: 0.1169 - f1-score: 0.1563 - val_loss: 0.7926 - val_Dice_coef: 0.3961 - val_iou_score: 0.1061 - val_f1-score: 0.1417\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.69899\n",
      "Epoch 11/2000000\n",
      "1000/1000 [==============================] - 543s 543ms/step - loss: 0.8911 - Dice_coef: 0.4320 - iou_score: 0.1124 - f1-score: 0.1512 - val_loss: 0.8889 - val_Dice_coef: 0.4229 - val_iou_score: 0.1061 - val_f1-score: 0.1428\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.69899\n",
      "Epoch 12/2000000\n",
      "1000/1000 [==============================] - 542s 542ms/step - loss: 0.8838 - Dice_coef: 0.4375 - iou_score: 0.1176 - f1-score: 0.1565 - val_loss: 0.9251 - val_Dice_coef: 0.3876 - val_iou_score: 0.0961 - val_f1-score: 0.1291\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.69899\n",
      "Epoch 13/2000000\n",
      "1000/1000 [==============================] - 545s 545ms/step - loss: 0.8796 - Dice_coef: 0.4391 - iou_score: 0.1213 - f1-score: 0.1606 - val_loss: 0.8670 - val_Dice_coef: 0.3678 - val_iou_score: 0.0902 - val_f1-score: 0.1239\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.69899\n",
      "Epoch 14/2000000\n",
      "1000/1000 [==============================] - 540s 540ms/step - loss: 0.8816 - Dice_coef: 0.4343 - iou_score: 0.1182 - f1-score: 0.1583 - val_loss: 0.9758 - val_Dice_coef: 0.4166 - val_iou_score: 0.1200 - val_f1-score: 0.1584\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.69899\n",
      "Epoch 15/2000000\n",
      "1000/1000 [==============================] - 542s 542ms/step - loss: 0.8859 - Dice_coef: 0.4301 - iou_score: 0.1163 - f1-score: 0.1544 - val_loss: 0.8753 - val_Dice_coef: 0.4399 - val_iou_score: 0.1209 - val_f1-score: 0.1610\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.69899\n",
      "Epoch 16/2000000\n",
      "1000/1000 [==============================] - 541s 541ms/step - loss: 0.8792 - Dice_coef: 0.4399 - iou_score: 0.1209 - f1-score: 0.1602 - val_loss: 1.0076 - val_Dice_coef: 0.4615 - val_iou_score: 0.1253 - val_f1-score: 0.1654\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.69899\n",
      "Epoch 17/2000000\n",
      "1000/1000 [==============================] - 542s 542ms/step - loss: 0.8796 - Dice_coef: 0.4473 - iou_score: 0.1204 - f1-score: 0.1592 - val_loss: 0.8676 - val_Dice_coef: 0.4342 - val_iou_score: 0.1249 - val_f1-score: 0.1633\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.69899\n",
      "Epoch 18/2000000\n",
      "1000/1000 [==============================] - 541s 541ms/step - loss: 0.8816 - Dice_coef: 0.4407 - iou_score: 0.1189 - f1-score: 0.1584 - val_loss: 0.7311 - val_Dice_coef: 0.4299 - val_iou_score: 0.1175 - val_f1-score: 0.1544\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.69899\n",
      "Epoch 19/2000000\n",
      "1000/1000 [==============================] - 542s 542ms/step - loss: 0.8736 - Dice_coef: 0.4538 - iou_score: 0.1258 - f1-score: 0.1659 - val_loss: 0.9320 - val_Dice_coef: 0.4571 - val_iou_score: 0.1192 - val_f1-score: 0.1554\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.69899\n",
      "Epoch 20/2000000\n",
      "1000/1000 [==============================] - 541s 541ms/step - loss: 0.8747 - Dice_coef: 0.4513 - iou_score: 0.1249 - f1-score: 0.1647 - val_loss: 0.8624 - val_Dice_coef: 0.4444 - val_iou_score: 0.1192 - val_f1-score: 0.1568\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.69899\n",
      "Epoch 21/2000000\n",
      "1000/1000 [==============================] - 539s 539ms/step - loss: 0.8644 - Dice_coef: 0.4680 - iou_score: 0.1336 - f1-score: 0.1753 - val_loss: 1.0046 - val_Dice_coef: 0.4439 - val_iou_score: 0.1164 - val_f1-score: 0.1507\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.69899\n",
      "Epoch 22/2000000\n",
      "1000/1000 [==============================] - 541s 541ms/step - loss: 0.8803 - Dice_coef: 0.4335 - iou_score: 0.1207 - f1-score: 0.1596 - val_loss: 1.0085 - val_Dice_coef: 0.4614 - val_iou_score: 0.1229 - val_f1-score: 0.1594\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.69899\n",
      "Epoch 23/2000000\n",
      "1000/1000 [==============================] - 543s 543ms/step - loss: 0.8657 - Dice_coef: 0.4731 - iou_score: 0.1319 - f1-score: 0.1721 - val_loss: 0.9240 - val_Dice_coef: 0.4549 - val_iou_score: 0.1216 - val_f1-score: 0.1602\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.69899\n"
     ]
    }
   ],
   "source": [
    "history2 = model.fit_generator(\n",
    "    train_generator, steps_per_epoch=1000, epochs=2000000,\n",
    "    validation_data=val_generator, validation_steps=500,\n",
    "    callbacks=[checkpoint,EarlyStopping(patience=20)],\n",
    "    use_multiprocessing=True,\n",
    "    workers=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/2000000\n",
      "100/100 [==============================] - 284s 3s/step - loss: 0.7246 - Dice_coef: 0.9258 - iou_score: 0.2448 - val_loss: 0.7091 - val_Dice_coef: 0.9446 - val_iou_score: 0.2571\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.52859\n",
      "Epoch 28/2000000\n",
      "100/100 [==============================] - 286s 3s/step - loss: 0.7239 - Dice_coef: 0.9370 - iou_score: 0.2454 - val_loss: 0.7996 - val_Dice_coef: 0.9237 - val_iou_score: 0.2598\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.52859\n",
      "Epoch 29/2000000\n",
      "100/100 [==============================] - 284s 3s/step - loss: 0.7101 - Dice_coef: 0.9507 - iou_score: 0.2603 - val_loss: 0.6247 - val_Dice_coef: 0.9110 - val_iou_score: 0.2381\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.52859\n",
      "Epoch 30/2000000\n",
      "100/100 [==============================] - 285s 3s/step - loss: 0.7261 - Dice_coef: 0.9381 - iou_score: 0.2436 - val_loss: 0.8105 - val_Dice_coef: 0.9208 - val_iou_score: 0.2355\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.52859\n",
      "Epoch 31/2000000\n",
      "100/100 [==============================] - 284s 3s/step - loss: 0.7197 - Dice_coef: 0.9454 - iou_score: 0.2507 - val_loss: 0.6789 - val_Dice_coef: 0.9594 - val_iou_score: 0.2515\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.52859\n",
      "Epoch 32/2000000\n",
      "100/100 [==============================] - 288s 3s/step - loss: 0.7159 - Dice_coef: 0.9415 - iou_score: 0.2524 - val_loss: 0.6452 - val_Dice_coef: 0.9403 - val_iou_score: 0.2671\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.52859\n",
      "Epoch 33/2000000\n",
      "100/100 [==============================] - 277s 3s/step - loss: 0.7100 - Dice_coef: 0.9428 - iou_score: 0.2588 - val_loss: 0.8011 - val_Dice_coef: 0.9576 - val_iou_score: 0.2717\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.52859\n",
      "Epoch 34/2000000\n",
      "100/100 [==============================] - 288s 3s/step - loss: 0.4161 - Dice_coef: 0.9404 - iou_score: 0.5589 - val_loss: 0.3843 - val_Dice_coef: 0.9116 - val_iou_score: 0.5917\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.52859 to 0.38432, saving model to model_10221101.h5\n",
      "Epoch 35/2000000\n",
      "100/100 [==============================] - 285s 3s/step - loss: 0.3600 - Dice_coef: 0.9417 - iou_score: 0.6099 - val_loss: 0.0733 - val_Dice_coef: 0.9543 - val_iou_score: 0.6458\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.38432 to 0.07327, saving model to model_10221101.h5\n",
      "Epoch 36/2000000\n",
      "100/100 [==============================] - 291s 3s/step - loss: 0.3732 - Dice_coef: 0.9431 - iou_score: 0.6012 - val_loss: 0.4451 - val_Dice_coef: 0.9591 - val_iou_score: 0.6236\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.07327\n",
      "Epoch 37/2000000\n",
      "100/100 [==============================] - 286s 3s/step - loss: 0.3423 - Dice_coef: 0.9435 - iou_score: 0.6252 - val_loss: 0.2488 - val_Dice_coef: 0.9399 - val_iou_score: 0.6260\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.07327\n",
      "Epoch 38/2000000\n",
      "100/100 [==============================] - 285s 3s/step - loss: 0.3493 - Dice_coef: 0.9367 - iou_score: 0.6205 - val_loss: 0.5200 - val_Dice_coef: 0.9414 - val_iou_score: 0.6514\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.07327\n",
      "Epoch 39/2000000\n",
      "100/100 [==============================] - 284s 3s/step - loss: 0.3633 - Dice_coef: 0.9447 - iou_score: 0.6085 - val_loss: 0.1729 - val_Dice_coef: 0.9189 - val_iou_score: 0.6634\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.07327\n",
      "Epoch 40/2000000\n",
      "100/100 [==============================] - 284s 3s/step - loss: 0.3473 - Dice_coef: 0.9509 - iou_score: 0.6231 - val_loss: 0.1394 - val_Dice_coef: 0.9228 - val_iou_score: 0.6430\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.07327\n",
      "Epoch 41/2000000\n",
      "100/100 [==============================] - 283s 3s/step - loss: 0.3474 - Dice_coef: 0.9473 - iou_score: 0.6228 - val_loss: 0.2966 - val_Dice_coef: 0.9498 - val_iou_score: 0.6205\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.07327\n",
      "Epoch 42/2000000\n",
      "100/100 [==============================] - 282s 3s/step - loss: 0.3402 - Dice_coef: 0.9461 - iou_score: 0.6297 - val_loss: 0.2488 - val_Dice_coef: 0.9335 - val_iou_score: 0.6271\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.07327\n",
      "Epoch 43/2000000\n",
      "100/100 [==============================] - 283s 3s/step - loss: 0.3491 - Dice_coef: 0.9476 - iou_score: 0.6223 - val_loss: 0.2760 - val_Dice_coef: 0.9646 - val_iou_score: 0.6246\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.07327\n",
      "Epoch 44/2000000\n",
      "100/100 [==============================] - 282s 3s/step - loss: 0.3466 - Dice_coef: 0.9480 - iou_score: 0.6222 - val_loss: 0.3957 - val_Dice_coef: 0.9206 - val_iou_score: 0.5915\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.07327\n",
      "Epoch 45/2000000\n",
      "100/100 [==============================] - 282s 3s/step - loss: 0.3564 - Dice_coef: 0.9529 - iou_score: 0.6166 - val_loss: 0.2615 - val_Dice_coef: 0.9343 - val_iou_score: 0.6273\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.07327\n"
     ]
    }
   ],
   "source": [
    "history2 = model.fit_generator(\n",
    "    train_generator, steps_per_epoch=100, epochs=2000000,\n",
    "    validation_data=val_generator, validation_steps=50,\n",
    "    callbacks=[checkpoint,EarlyStopping(patience=10)],\n",
    "    use_multiprocessing=True,initial_epoch=26,\n",
    "    workers=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_string = model.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Writing JSON data\n",
    "with open('model_05.json', 'w') as f:\n",
    "    json.dump(json_string, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "171px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
